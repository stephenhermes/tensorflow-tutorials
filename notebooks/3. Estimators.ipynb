{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimators\n",
    "\n",
    "The actual model is contained in a `tf.estimator.Estimator` instance. In this notebook we will work with the premade TensorFlow estimators. Estimators have a Scikit-Learn style api, where there are methods for `train`, `evaluate`, and `predict`. \n",
    "\n",
    "Estimators automatically provide many features that would have to be hand-coded in otherwise. Two features worth highlighting are:\n",
    "1. Logging and checkpointing as the model trains\n",
    "2. Distributing the computation graph for training on the cloud.\n",
    "\n",
    "The idea behind working with Estimators is that the only things about the computation graph that need to change between the three different phases of machine learning are all about how and what data is fed into the model. For example, during training we iterate for many epochs, while evaluation and prediction we don't; for training and evaluation we have labels in addition to features while for prediction we only have features.\n",
    "\n",
    "The way TensorFlow handles this is that each method takes as input an `input_fn` which is a function that takes no inputs and returns ops to be added to the graph. **Note** when training for example, the `input_fn` is not called on each batch of data or anything like that. It is called only once, and used to add nodes to the computation graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pathlib\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Prepare data\n",
    "\n",
    "We need to split our data into train and evaluation datasets. A good design pattern with sharded data is to make separate folders for training and evaluation data. A bad design pattern is to not randomize what is train data and what is test data, but none-the-less we will just set aside `boston-0.csv` as test data and the rest as train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path('data/sharded_data')\n",
    "train_dir = data_dir.parent / 'train'\n",
    "test_dir = data_dir.parent / 'test'\n",
    "\n",
    "if not train_dir.exists():\n",
    "    train_dir.mkdir()\n",
    "if not test_dir.exists():\n",
    "    test_dir.mkdir()\n",
    "    \n",
    "for f in data_dir.glob('*.csv'):\n",
    "    if f.stem.endswith('0'):\n",
    "        shutil.copyfile(f, test_dir / f.name)\n",
    "    else:\n",
    "        shutil.copyfile(f, train_dir / f.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Estimator setup\n",
    "\n",
    "Estimators take feature columns as one of the inputs to their constructors, so let's start off by instantiating the feature columns we will be using in our model. Since all of our csv files have the same schema, we can load in a few rows of one using pandas to get some useful information about the data we're ingesting into out model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.08370</td>\n",
       "      <td>45.0</td>\n",
       "      <td>3.44</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.4370</td>\n",
       "      <td>7.185</td>\n",
       "      <td>38.9</td>\n",
       "      <td>4.5667</td>\n",
       "      <td>5</td>\n",
       "      <td>398.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.39</td>\n",
       "      <td>34.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05023</td>\n",
       "      <td>35.0</td>\n",
       "      <td>6.06</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.4379</td>\n",
       "      <td>5.706</td>\n",
       "      <td>28.4</td>\n",
       "      <td>6.6407</td>\n",
       "      <td>1</td>\n",
       "      <td>304.0</td>\n",
       "      <td>16.9</td>\n",
       "      <td>394.02</td>\n",
       "      <td>12.43</td>\n",
       "      <td>17.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.03961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.19</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.5150</td>\n",
       "      <td>6.037</td>\n",
       "      <td>34.5</td>\n",
       "      <td>5.9853</td>\n",
       "      <td>5</td>\n",
       "      <td>224.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>8.01</td>\n",
       "      <td>21.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.38799</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.5380</td>\n",
       "      <td>5.950</td>\n",
       "      <td>82.0</td>\n",
       "      <td>3.9900</td>\n",
       "      <td>4</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>232.60</td>\n",
       "      <td>27.71</td>\n",
       "      <td>13.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.35472</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.5380</td>\n",
       "      <td>6.072</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.1750</td>\n",
       "      <td>4</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>376.73</td>\n",
       "      <td>13.04</td>\n",
       "      <td>14.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus chas     nox     rm    age     dis  rad    tax  \\\n",
       "0  0.08370  45.0   3.44    Y  0.4370  7.185   38.9  4.5667    5  398.0   \n",
       "1  0.05023  35.0   6.06    Y  0.4379  5.706   28.4  6.6407    1  304.0   \n",
       "2  0.03961   0.0   5.19    Y  0.5150  6.037   34.5  5.9853    5  224.0   \n",
       "3  1.38799   0.0   8.14    Y  0.5380  5.950   82.0  3.9900    4  307.0   \n",
       "4  1.35472   0.0   8.14    Y  0.5380  6.072  100.0  4.1750    4  307.0   \n",
       "\n",
       "   ptratio       b  lstat  target  \n",
       "0     15.2  396.90   5.39    34.9  \n",
       "1     16.9  394.02  12.43    17.1  \n",
       "2     20.2  396.90   8.01    21.1  \n",
       "3     21.0  232.60  27.71    13.2  \n",
       "4     21.0  376.73  13.04    14.5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = pathlib.Path('data/sharded_data')\n",
    "file = (data_dir / 'boston-0.csv').as_posix()\n",
    "\n",
    "df = pd.read_csv(file, nrows=10)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_columns = list(df.columns)\n",
    "label_col = 'target'\n",
    "# Decoding the csv requires a list of default values to use for each tensor\n",
    "# produced. The defaults are passed as a list of lists.\n",
    "default_values = [[0.0]] * 14\n",
    "default_values[3] = ['_UNKNOWN']; default_values[8] = 0\n",
    "# Get columns different dtypes\n",
    "feature_cols = [c for c in csv_columns if c != label_col]\n",
    "byte_cols = ['chas']\n",
    "int64_cols = ['rad']\n",
    "float_cols = [c for c in feature_cols if c not in int64_cols and c not in byte_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make feature columns\n",
    "byte_cols = [\n",
    "    tf.feature_column.indicator_column(\n",
    "            tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            name, ['Y', 'N']\n",
    "        )\n",
    "    )\n",
    "    for name in byte_cols\n",
    "]\n",
    "int64_cols = [\n",
    "    tf.feature_column.numeric_column(name, dtype=tf.int64)\n",
    "    for name in int64_cols\n",
    "]\n",
    "float_cols = [\n",
    "    tf.feature_column.numeric_column(name, dtype=tf.float32)\n",
    "    for name in float_cols\n",
    "]\n",
    "feature_columns = byte_cols + int64_cols + float_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one more optional component to setup for our model, namely the configuration details of the model. To evaluate the model's performance we will want to examine the its train and test error. This requires us to set some configurations in advance.\n",
    "\n",
    "As TensorFlow models train, they write checkpoints after however many steps or hours of training. By default, `Estimator`s are configured to only write a checkpoint once when training is complete. However, evaluations metrics, such as test error, are only computed during checkpoints. Thus to get a test loss curve, we need to set our model to save multiple checkpoints.\n",
    "\n",
    "\n",
    "Setting runtime configuration for our the model is done by passing a `tf.estimator.RunConfig` object to the estimator. Below we set the `RunConfig` to save multiple checkpoints.\n",
    "\n",
    "**Aside:** One of the things that is a bit strange about working in TensorFlow is that a lot configuration and parameters are set by passing various objects which hold configuration and specification details. This is a drastic contrast from, say, Scikit Learn where configurations are set by passing strings or numeric values to an estimator/transformer or whatever. Moreover in Scikit Learn, there are only a few base classes one works with, and a standardized API. \n",
    "\n",
    "With TensorFlow estimators, there is a lot more flexibility in how things are configured, and accordingly, more complicated objects used to configure them. These configuration objects are mostly glorified holders for key/value pairs and don't have methods that a user would typically access. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'models\\\\model_20190302_144436', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001F53E8876A0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model_dir = pathlib.Path('models')\n",
    "if not model_dir.exists():\n",
    "    model_dir.mkdir()\n",
    "\n",
    "model_dir = model_dir / datetime.datetime.now().strftime('model_%Y%m%d_%H%M%S/')\n",
    "\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    save_checkpoints_steps=100,\n",
    "    keep_checkpoint_max=20,\n",
    ")\n",
    "\n",
    "estimator = tf.estimator.LinearRegressor(\n",
    "    feature_columns,\n",
    "    model_dir=model_dir,\n",
    "    config=run_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on, let's recap what the dataset we produced before is doing. In particular, we use defined a function `parse_row` which takes a rstring tensor and returns a tuple of tensors, one for each column of the csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 2.37857, 14.4208 ], dtype=float32), array([0., 0.], dtype=float32), array([18.1, 18.1], dtype=float32), array([b'Y', b'Y'], dtype=object), array([0.583, 0.74 ], dtype=float32), array([5.871, 6.461], dtype=float32), array([41.9, 93.3], dtype=float32), array([3.724 , 2.0026], dtype=float32), array([24, 24]), array([666., 666.], dtype=float32), array([20.2, 20.2], dtype=float32), array([370.73,  27.49], dtype=float32), array([13.34, 18.05], dtype=float32), array([20.6,  9.6], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "data_dir = pathlib.Path('data')\n",
    "files = (data_dir / 'train' / 'boston-*.csv').as_posix()\n",
    "\n",
    "# Training parameters\n",
    "n_epochs = 10\n",
    "batch_size = 2\n",
    "\n",
    "def parse_row(row):\n",
    "    return tf.decode_csv(row, record_defaults=default_values)\n",
    "\n",
    "# Build data set\n",
    "dataset = tf.data.Dataset.list_files(files)\n",
    "dataset = dataset.flat_map(lambda f: tf.data.TextLineDataset(f).skip(1))\n",
    "dataset = dataset.map(parse_row)\n",
    "# Repeat the dataset\n",
    "dataset = dataset.repeat(n_epochs)\n",
    "# Shuffle data\n",
    "dataset = dataset.shuffle(buffer_size=1024)\n",
    "# Get a batch of data\n",
    "dataset = dataset.batch(batch_size)\n",
    "# Preload next batch to speed up training\n",
    "dataset = dataset.prefetch(buffer_size=batch_size)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "batch = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    batch1 = sess.run(batch)\n",
    "\n",
    "# Just getting a dataset of individual file names\n",
    "print(batch1)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training\n",
    "\n",
    "During training and evaluation, data is fed to the estimator as a tuple of features and labels. The features should be in a dict, where the key matches the name of the corresponding `tf.feature_column` feature column the training instance gets sent to. The main thing we need to change about our curent dataset implementation is that instead of `parse_row` returning a tuple of all of the csv folumns, it needs to return these tuples. We also need to only take in training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'crim': array([28.6558 ,  0.06466], dtype=float32), 'zn': array([ 0., 70.], dtype=float32), 'indus': array([18.1 ,  2.24], dtype=float32), 'chas': array([b'Y', b'Y'], dtype=object), 'nox': array([0.597, 0.4  ], dtype=float32), 'rm': array([5.155, 6.345], dtype=float32), 'age': array([100. ,  20.1], dtype=float32), 'dis': array([1.5894, 7.8278], dtype=float32), 'rad': array([24,  5]), 'tax': array([666., 358.], dtype=float32), 'ptratio': array([20.2, 14.8], dtype=float32), 'b': array([210.97, 368.24], dtype=float32), 'lstat': array([20.08,  4.97], dtype=float32)}, array([16.3, 22.5], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "def parse_row(row):\n",
    "    # Get tuple of csv row\n",
    "    parsed = tf.decode_csv(row, record_defaults=default_values)\n",
    "    # Get dict of col_name: value pairs\n",
    "    features = dict(zip(csv_columns, parsed))\n",
    "    # Remove label from features\n",
    "    label = features.pop(label_col)\n",
    "    return features, label\n",
    "\n",
    "# File for training\n",
    "files = (data_dir / 'train' / 'boston-*.csv').as_posix()\n",
    "\n",
    "# Build data set\n",
    "dataset = tf.data.Dataset.list_files(files)\n",
    "dataset = dataset.flat_map(lambda f: tf.data.TextLineDataset(f).skip(1))\n",
    "dataset = dataset.map(parse_row)\n",
    "# Repeat the dataset\n",
    "dataset = dataset.repeat(n_epochs)\n",
    "# Shuffle data\n",
    "dataset = dataset.shuffle(buffer_size=1024)\n",
    "# Get a batch of data\n",
    "dataset = dataset.batch(batch_size)\n",
    "# Preload next batch to speed up training\n",
    "dataset = dataset.prefetch(buffer_size=batch_size)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "batch = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    batch1 = sess.run(batch)\n",
    "\n",
    "# Now we get a (dict, value) pair\n",
    "print(batch1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap in a train input_fn\n",
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "\n",
    "def train_input_fn():\n",
    "    # Files for training\n",
    "    files = (data_dir / 'train' / 'boston-*.csv').as_posix()\n",
    "    # Build data set\n",
    "    dataset = tf.data.Dataset.list_files(files)\n",
    "    dataset = dataset.flat_map(lambda f: tf.data.TextLineDataset(f).skip(1))\n",
    "    dataset = dataset.map(parse_row)\n",
    "    # Repeat the dataset\n",
    "    dataset = dataset.repeat(n_epochs)\n",
    "    # Shuffle data\n",
    "    dataset = dataset.shuffle(buffer_size=1024)\n",
    "    # Get a batch of data\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    # Preload next batch to speed up training\n",
    "    dataset = dataset.prefetch(buffer_size=batch_size)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    features, label = iterator.get_next()\n",
    "    return features, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\stephen.hermes\\desktop\\tensorflow\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From c:\\users\\stephen.hermes\\desktop\\tensorflow\\venv\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2703: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From c:\\users\\stephen.hermes\\desktop\\tensorflow\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\lookup_ops.py:1137: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From c:\\users\\stephen.hermes\\desktop\\tensorflow\\venv\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:4266: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From c:\\users\\stephen.hermes\\desktop\\tensorflow\\venv\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:4321: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into models\\model_20190302_144436\\model.ckpt.\n",
      "INFO:tensorflow:loss = 18183.35, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 64 into models\\model_20190302_144436\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 684.8249.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.linear.LinearRegressor at 0x1f53e887ba8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train that bad boy on all of the data\n",
    "estimator.train(input_fn=train_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluate\n",
    "\n",
    "Similar deal, but we don't need to shuffle the data or run for multiple epochs. We also need to take our data from a different directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap in a train input_fn\n",
    "n_epochs = 1\n",
    "batch_size = 32\n",
    "\n",
    "def eval_input_fn():\n",
    "    # Files for training\n",
    "    files = (data_dir / 'test' / 'boston-*.csv').as_posix()\n",
    "    # Build data set\n",
    "    dataset = tf.data.Dataset.list_files(files)\n",
    "    dataset = dataset.flat_map(lambda f: tf.data.TextLineDataset(f).skip(1))\n",
    "    dataset = dataset.map(parse_row)\n",
    "    # Repeat the dataset\n",
    "    dataset = dataset.repeat(n_epochs)\n",
    "    # Shuffle data\n",
    "    # dataset = dataset.shuffle(buffer_size=1024)\n",
    "    # Get a batch of data\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    # Preload next batch to speed up training\n",
    "    dataset = dataset.prefetch(buffer_size=batch_size)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    features, label = iterator.get_next()\n",
    "    return features, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-02T19:44:40Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From c:\\users\\stephen.hermes\\desktop\\tensorflow\\venv\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from models\\model_20190302_144436\\model.ckpt-64\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-02-19:44:40\n",
      "INFO:tensorflow:Saving dict for global step 64: average_loss = 83.72892, global_step = 64, label/mean = 23.321783, loss = 2114.1553, prediction/mean = 23.39104\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 64: models\\model_20190302_144436\\model.ckpt-64\n"
     ]
    }
   ],
   "source": [
    "metrics = estimator.evaluate(input_fn=eval_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_loss: 83.72891998291016\n",
      "label/mean: 23.3217830657959\n",
      "loss: 2114.1552734375\n",
      "prediction/mean: 23.391040802001953\n",
      "global_step: 64\n"
     ]
    }
   ],
   "source": [
    "for k, v in metrics.items():\n",
    "    print('{0}: {1}'.format(k, v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Predict\n",
    "\n",
    "Guess. The output of the `predict` method is an iterator of the results, with each result being a dict with a `'predictions'` key and value the predicted value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap in a train input_fn\n",
    "n_epochs = 1\n",
    "batch_size = 32\n",
    "\n",
    "def pred_input_fn():\n",
    "   # Files for training\n",
    "    files = (data_dir / 'test' / 'boston-*.csv').as_posix()\n",
    "    # Build data set\n",
    "    dataset = tf.data.Dataset.list_files(files)\n",
    "    dataset = dataset.flat_map(lambda f: tf.data.TextLineDataset(f).skip(1))\n",
    "    dataset = dataset.map(parse_row)\n",
    "    # Repeat the dataset\n",
    "    dataset = dataset.repeat(n_epochs)\n",
    "    # Shuffle data\n",
    "    # dataset = dataset.shuffle(buffer_size=1024)\n",
    "    # Get a batch of data\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    # Preload next batch to speed up training\n",
    "    dataset = dataset.prefetch(buffer_size=batch_size)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    features, label = iterator.get_next()\n",
    "    # We could actually also return the labels here; they would get ignored.\n",
    "    # The commented out returns all work\n",
    "    \n",
    "    # return features, label\n",
    "    # return features, None\n",
    "    return features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = estimator.predict(input_fn=pred_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from models\\model_20190302_144436\\model.ckpt-64\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "{'predictions': array([28.807257], dtype=float32)}\n",
      "{'predictions': array([26.307745], dtype=float32)}\n",
      "{'predictions': array([23.498741], dtype=float32)}\n",
      "{'predictions': array([15.082013], dtype=float32)}\n",
      "{'predictions': array([24.148497], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    print(next(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from models\\model_20190302_144436\\model.ckpt-64\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "# Examining the results\n",
    "file = data_dir / 'test' / 'boston-0.csv'\n",
    "df = pd.read_csv(file)\n",
    "# Need to re-predict since we used up some of the iterator...\n",
    "predictions = estimator.predict(input_fn=pred_input_fn)\n",
    "\n",
    "df['predicted'] = np.array(list(x['predictions'][0] for x in predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "      <th>target</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.08370</td>\n",
       "      <td>45.0</td>\n",
       "      <td>3.44</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.4370</td>\n",
       "      <td>7.185</td>\n",
       "      <td>38.9</td>\n",
       "      <td>4.5667</td>\n",
       "      <td>5</td>\n",
       "      <td>398.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.39</td>\n",
       "      <td>34.9</td>\n",
       "      <td>28.807257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05023</td>\n",
       "      <td>35.0</td>\n",
       "      <td>6.06</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.4379</td>\n",
       "      <td>5.706</td>\n",
       "      <td>28.4</td>\n",
       "      <td>6.6407</td>\n",
       "      <td>1</td>\n",
       "      <td>304.0</td>\n",
       "      <td>16.9</td>\n",
       "      <td>394.02</td>\n",
       "      <td>12.43</td>\n",
       "      <td>17.1</td>\n",
       "      <td>26.307745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.03961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.19</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.5150</td>\n",
       "      <td>6.037</td>\n",
       "      <td>34.5</td>\n",
       "      <td>5.9853</td>\n",
       "      <td>5</td>\n",
       "      <td>224.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>8.01</td>\n",
       "      <td>21.1</td>\n",
       "      <td>23.498741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.38799</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.5380</td>\n",
       "      <td>5.950</td>\n",
       "      <td>82.0</td>\n",
       "      <td>3.9900</td>\n",
       "      <td>4</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>232.60</td>\n",
       "      <td>27.71</td>\n",
       "      <td>13.2</td>\n",
       "      <td>15.082013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.35472</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.5380</td>\n",
       "      <td>6.072</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.1750</td>\n",
       "      <td>4</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>376.73</td>\n",
       "      <td>13.04</td>\n",
       "      <td>14.5</td>\n",
       "      <td>24.148497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus chas     nox     rm    age     dis  rad    tax  \\\n",
       "0  0.08370  45.0   3.44    Y  0.4370  7.185   38.9  4.5667    5  398.0   \n",
       "1  0.05023  35.0   6.06    Y  0.4379  5.706   28.4  6.6407    1  304.0   \n",
       "2  0.03961   0.0   5.19    Y  0.5150  6.037   34.5  5.9853    5  224.0   \n",
       "3  1.38799   0.0   8.14    Y  0.5380  5.950   82.0  3.9900    4  307.0   \n",
       "4  1.35472   0.0   8.14    Y  0.5380  6.072  100.0  4.1750    4  307.0   \n",
       "\n",
       "   ptratio       b  lstat  target  predicted  \n",
       "0     15.2  396.90   5.39    34.9  28.807257  \n",
       "1     16.9  394.02  12.43    17.1  26.307745  \n",
       "2     20.2  396.90   8.01    21.1  23.498741  \n",
       "3     21.0  232.60  27.71    13.2  15.082013  \n",
       "4     21.0  376.73  13.04    14.5  24.148497  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 83.7289246990946\n"
     ]
    }
   ],
   "source": [
    "# Note this is basically the same value as what the eval did.\n",
    "mse = ((df['target'] - df['predicted']) ** 2).mean()\n",
    "print('mse:', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Better design patterns\n",
    "\n",
    "Clearly all of the different `input_fn` that needed to be made differ superficially. A better pattern is to make a genric function that can return different dataset ops depending on what we want to do with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generic_input_fn(file, batch_size=32, n_repeat=1, shuffle=False, return_labels=False):\n",
    "    # Build data set\n",
    "    dataset = tf.data.Dataset.list_files(file)\n",
    "    dataset = dataset.flat_map(lambda f: tf.data.TextLineDataset(f).skip(1))\n",
    "    dataset = dataset.map(parse_row)\n",
    "    dataset = dataset.repeat(n_repeat)\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=1024)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=batch_size)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    features, label = iterator.get_next()\n",
    "    if not return_labels:\n",
    "        label = None\n",
    "    return features, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can either use `lambda` function to make the desired `input_fn`, or wrap the above function in a function factory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-02T19:44:43Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from models\\model_20190302_144436\\model.ckpt-64\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-02-19:44:43\n",
      "INFO:tensorflow:Saving dict for global step 64: average_loss = 83.72892, global_step = 64, label/mean = 23.321783, loss = 2114.1553, prediction/mean = 23.39104\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 64: models\\model_20190302_144436\\model.ckpt-64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'average_loss': 83.72892,\n",
       " 'label/mean': 23.321783,\n",
       " 'loss': 2114.1553,\n",
       " 'prediction/mean': 23.39104,\n",
       " 'global_step': 64}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lambda example:\n",
    "file = (data_dir / 'test' / 'boston-*.csv').as_posix()\n",
    "estimator.evaluate(input_fn=lambda: generic_input_fn(file, return_labels=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function factory example:\n",
    "def get_input_fn(mode):\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        files = (data_dir / 'train' / 'boston-*.csv').as_posix()\n",
    "        return lambda: generic_input_fn(\n",
    "            files, \n",
    "            batch_size=32, \n",
    "            n_repeat=100, \n",
    "            shuffle=True, \n",
    "            return_labels=True\n",
    "        )\n",
    "    elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "        files = (data_dir / 'test' / 'boston-*.csv').as_posix()\n",
    "        return lambda: generic_input_fn(\n",
    "            files, \n",
    "            batch_size=32, \n",
    "            n_repeat=20, \n",
    "            shuffle=False, \n",
    "            return_labels=True\n",
    "        )\n",
    "    elif mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        files = (data_dir / 'test' / 'boston-*.csv').as_posix()\n",
    "        return lambda: generic_input_fn(\n",
    "            files, \n",
    "            batch_size=32, \n",
    "            n_repeat=1, \n",
    "            shuffle=False, \n",
    "            return_labels=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-02T19:44:44Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from models\\model_20190302_144436\\model.ckpt-64\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-02-19:44:44\n",
      "INFO:tensorflow:Saving dict for global step 64: average_loss = 83.728905, global_step = 64, label/mean = 23.321775, loss = 2642.6936, prediction/mean = 23.391035\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 64: models\\model_20190302_144436\\model.ckpt-64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'average_loss': 83.728905,\n",
       " 'label/mean': 23.321775,\n",
       " 'loss': 2642.6936,\n",
       " 'prediction/mean': 23.391035,\n",
       " 'global_step': 64}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.evaluate(input_fn=get_input_fn(tf.estimator.ModeKeys.EVAL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the function factory implementation we used the `ModeKeys` object, which is basically just an object whose attributes are standardized names for training, evaluation, and prediction phases (to avoid things like one person's code using `'eval'` vs. another person's code using `'test'`, etc.)\n",
    "\n",
    "## 6. Train and evaluate\n",
    "\n",
    "Lastly, TensorFlow provides a utility function `tf.estimator.train_and_evaluate` which trains the model, then evaluates it. Why not just do those two steps one after the other as above you ask? According to the TensorFlow documentation, `train_and_evaluate` provides consistent behavior for both local and distributed training/evaluation. In particular, it let's us test out our model training and evaluation pipelines locally, and get the same behavior when we move to the cloud to train with Cloud ML Engine.\n",
    "\n",
    "**Note** In the olden days, CMLE worked by running an instance of the TensorFlow `Experiment` class, which is now deprecated. This class was replaced by the `train_and_evaluate` function. You will run across examples using the `Experiment` class online. Ignore them.\n",
    "\n",
    "In order to use `train_and_evaluate` we need to pass to it specifications for how training and evaluation should run. These are controlled by `TrainSpec` and `EvalSpec` objects, respectively. It is best to think of these objects as just packages of parameters and not worry about them too much. They don't functionality as things in their own right.\n",
    "\n",
    "Both `TrainSpec` and `EvalSpec` take as their primary argument the corresponding `input_fn`. For `TrainSpec`, there is another argument for `max_steps` which specifies the maximum number of steps for which to train. If set to `None`, the TensorFlow documentation says that the model will train forever, but this is wrong. It trains until the dataset iterator throws an `OutOfRangeError`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from models\\model_20190302_144436\\model.ckpt-64\n",
      "WARNING:tensorflow:From c:\\users\\stephen.hermes\\desktop\\tensorflow\\venv\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 64 into models\\model_20190302_144436\\model.ckpt.\n",
      "INFO:tensorflow:loss = 1280.8647, step = 65\n",
      "INFO:tensorflow:global_step/sec: 522.504\n",
      "INFO:tensorflow:loss = 1219.2782, step = 165 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 735.654\n",
      "INFO:tensorflow:loss = 1354.4929, step = 265 (0.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 714.932\n",
      "INFO:tensorflow:loss = 2094.3552, step = 365 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 568.308\n",
      "INFO:tensorflow:loss = 1446.0485, step = 465 (0.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 638.65\n",
      "INFO:tensorflow:loss = 1116.3184, step = 565 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 677.475\n",
      "INFO:tensorflow:loss = 1038.4558, step = 665 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 721.303\n",
      "INFO:tensorflow:loss = 741.103, step = 765 (0.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 753.958\n",
      "INFO:tensorflow:loss = 1150.8945, step = 865 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 836.572\n",
      "INFO:tensorflow:loss = 1795.0957, step = 965 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 714.781\n",
      "INFO:tensorflow:loss = 2043.6622, step = 1065 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 759.602\n",
      "INFO:tensorflow:loss = 1131.856, step = 1165 (0.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 790.71\n",
      "INFO:tensorflow:loss = 2308.9436, step = 1265 (0.124 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1327 into models\\model_20190302_144436\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-02T19:45:53Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from models\\model_20190302_144436\\model.ckpt-1327\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-02-19:45:54\n",
      "INFO:tensorflow:Saving dict for global step 1327: average_loss = 46.249863, global_step = 1327, label/mean = 23.321775, loss = 1459.7612, prediction/mean = 23.53985\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1327: models\\model_20190302_144436\\model.ckpt-1327\n",
      "INFO:tensorflow:Loss for final step: 248.11682.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'average_loss': 46.249863,\n",
       "  'label/mean': 23.321775,\n",
       "  'loss': 1459.7612,\n",
       "  'prediction/mean': 23.53985,\n",
       "  'global_step': 1327},\n",
       " [])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_spec = tf.estimator.TrainSpec(\n",
    "    input_fn=get_input_fn(tf.estimator.ModeKeys.TRAIN),\n",
    "    max_steps=None\n",
    ")\n",
    "eval_spec = tf.estimator.EvalSpec(\n",
    "    input_fn=get_input_fn(\n",
    "        tf.estimator.ModeKeys.EVAL\n",
    "    )\n",
    ")\n",
    "tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also export the model for serving while using `train_and_evaluate`. To do so, we need to pass an `Exporter` to our `EvalSpec`. \n",
    "\n",
    "Just like how the `TrainSpec` and `EvalSpec` need an `input_fn` to know what nodes to add to the model's computation graph to prepare it for training and evaluation, the `Exporter` needs a `serving_input_fn` to know what nodes to add to the graph for serving predictions. There are a few different types of exporters\n",
    "\n",
    "You might think that we would just use the `prediction_input_fn` above for this `serving_input_fn`, but this isn't quite the case. Our `prediction_input_fn` is designed for ingesting in data from a file we have access to. When we serve the model on the cloud, predictions will be made by sending json requests to the server serving our model. Thus we need to add `tf.placeholder` nodes for input to the model, and some logic to parse a json request. This additional logic is handled by a `ServingInputReceiver` object. *I need to look into these more...*\n",
    "\n",
    "\n",
    "OKAY SO : Eval steps only called at checkpoints, so in tensorboard, you will have an eval metric point for each checkpoint. In the model_dir there is an initial checkpoint, which doesnt count and the rest are when the eval steps are called. so if ya want to print off an actual eval loss curve you need to set somethign to checkpoint more frequently\n",
    "\n",
    "According to Tensorflow documentdation:\n",
    "Checkpointing Frequency\n",
    "By default, the Estimator saves checkpoints in the model_dir according to the following schedule:\n",
    "\n",
    "Writes a checkpoint every 10 minutes (600 seconds).\n",
    "Writes a checkpoint when the train method starts (first iteration) and completes (final iteration).\n",
    "Retains only the 5 most recent checkpoints in the directory.\n",
    "You may alter the default schedule by taking the following steps:\n",
    "\n",
    "Create a tf.estimator.RunConfig object that defines the desired schedule.\n",
    "When instantiating the Estimator, pass that RunConfig object to the Estimator's config argument.\n",
    "For example, the following code changes the checkpointing schedule to every 20 minutes and retains the 10 most recent checkpoints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dtype(col):\n",
    "    # Not a great solution, but whatever\n",
    "    if col == 'chas':\n",
    "        return tf.string\n",
    "    elif col == 'rad':\n",
    "        return tf.int64\n",
    "    else:\n",
    "        return tf.float32\n",
    "\n",
    "def serving_input_fn():\n",
    "    # Expected json input\n",
    "    feature_placeholders = dict(\n",
    "        (col, tf.placeholder(get_dtype(col), (None))) for col in feature_cols\n",
    "    )\n",
    "    # Can do aditional transformations to prepare for model if needed\n",
    "    features = feature_placeholders\n",
    "    return tf.estimator.export.ServingInputReceiver(features, feature_placeholders)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'models\\\\model_20190302_144601', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 100, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 20, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001F544274668>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 100 or save_checkpoints_secs None.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into models\\model_20190302_144601\\model.ckpt.\n",
      "INFO:tensorflow:loss = 19799.12, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 100 into models\\model_20190302_144601\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-02T19:46:05Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from models\\model_20190302_144601\\model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-02-19:46:05\n",
      "INFO:tensorflow:Saving dict for global step 100: average_loss = 83.9864, global_step = 100, label/mean = 23.321775, loss = 2650.8206, prediction/mean = 20.756788\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 100: models\\model_20190302_144601\\model.ckpt-100\n",
      "INFO:tensorflow:global_step/sec: 60.9759\n",
      "INFO:tensorflow:loss = 1325.0828, step = 101 (1.646 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 200 into models\\model_20190302_144601\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-02T19:46:06Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from models\\model_20190302_144601\\model.ckpt-200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-02-19:46:07\n",
      "INFO:tensorflow:Saving dict for global step 200: average_loss = 72.3193, global_step = 200, label/mean = 23.321775, loss = 2282.578, prediction/mean = 21.574007\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 200: models\\model_20190302_144601\\model.ckpt-200\n",
      "INFO:tensorflow:global_step/sec: 69.3215\n",
      "INFO:tensorflow:loss = 1606.394, step = 201 (1.438 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 300 into models\\model_20190302_144601\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-02T19:46:08Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from models\\model_20190302_144601\\model.ckpt-300\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-02-19:46:08\n",
      "INFO:tensorflow:Saving dict for global step 300: average_loss = 63.558758, global_step = 300, label/mean = 23.321775, loss = 2006.0732, prediction/mean = 23.213953\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 300: models\\model_20190302_144601\\model.ckpt-300\n",
      "INFO:tensorflow:global_step/sec: 58.1811\n",
      "INFO:tensorflow:loss = 1411.5828, step = 301 (1.718 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 400 into models\\model_20190302_144601\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-02T19:46:09Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from models\\model_20190302_144601\\model.ckpt-400\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-02-19:46:10\n",
      "INFO:tensorflow:Saving dict for global step 400: average_loss = 61.13166, global_step = 400, label/mean = 23.321775, loss = 1929.468, prediction/mean = 23.088144\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 400: models\\model_20190302_144601\\model.ckpt-400\n",
      "INFO:tensorflow:global_step/sec: 62.2504\n",
      "INFO:tensorflow:loss = 1393.3832, step = 401 (1.607 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 500 into models\\model_20190302_144601\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-02T19:46:11Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from models\\model_20190302_144601\\model.ckpt-500\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-02-19:46:11\n",
      "INFO:tensorflow:Saving dict for global step 500: average_loss = 59.014496, global_step = 500, label/mean = 23.321775, loss = 1862.645, prediction/mean = 22.229248\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 500: models\\model_20190302_144601\\model.ckpt-500\n",
      "INFO:tensorflow:global_step/sec: 68.2998\n",
      "INFO:tensorflow:loss = 1968.477, step = 501 (1.464 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 600 into models\\model_20190302_144601\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-02T19:46:12Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from models\\model_20190302_144601\\model.ckpt-600\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-02-19:46:13\n",
      "INFO:tensorflow:Saving dict for global step 600: average_loss = 57.48839, global_step = 600, label/mean = 23.321775, loss = 1814.4774, prediction/mean = 24.358707\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 600: models\\model_20190302_144601\\model.ckpt-600\n",
      "INFO:tensorflow:global_step/sec: 57.4669\n",
      "INFO:tensorflow:loss = 1436.4304, step = 601 (1.739 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 700 into models\\model_20190302_144601\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-02T19:46:14Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from models\\model_20190302_144601\\model.ckpt-700\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-02-19:46:15\n",
      "INFO:tensorflow:Saving dict for global step 700: average_loss = 53.43649, global_step = 700, label/mean = 23.321775, loss = 1686.5892, prediction/mean = 22.005993\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 700: models\\model_20190302_144601\\model.ckpt-700\n",
      "INFO:tensorflow:global_step/sec: 69.1682\n",
      "INFO:tensorflow:loss = 530.1941, step = 701 (1.447 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 800 into models\\model_20190302_144601\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-02T19:46:16Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from models\\model_20190302_144601\\model.ckpt-800\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-02-19:46:16\n",
      "INFO:tensorflow:Saving dict for global step 800: average_loss = 54.42376, global_step = 800, label/mean = 23.321775, loss = 1717.7499, prediction/mean = 24.54124\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 800: models\\model_20190302_144601\\model.ckpt-800\n",
      "INFO:tensorflow:global_step/sec: 65.9619\n",
      "INFO:tensorflow:loss = 2009.5443, step = 801 (1.516 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 900 into models\\model_20190302_144601\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-02T19:46:17Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from models\\model_20190302_144601\\model.ckpt-900\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-02-19:46:18\n",
      "INFO:tensorflow:Saving dict for global step 900: average_loss = 52.11423, global_step = 900, label/mean = 23.321775, loss = 1644.8555, prediction/mean = 21.751625\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 900: models\\model_20190302_144601\\model.ckpt-900\n",
      "INFO:tensorflow:global_step/sec: 64.3584\n",
      "INFO:tensorflow:loss = 1272.9094, step = 901 (1.554 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into models\\model_20190302_144601\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-02T19:46:19Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from models\\model_20190302_144601\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-02-19:46:19\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 51.011395, global_step = 1000, label/mean = 23.321775, loss = 1610.0471, prediction/mean = 23.99853\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: models\\model_20190302_144601\\model.ckpt-1000\n",
      "INFO:tensorflow:global_step/sec: 66.974\n",
      "INFO:tensorflow:loss = 1896.4893, step = 1001 (1.492 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1100 into models\\model_20190302_144601\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-02T19:46:20Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from models\\model_20190302_144601\\model.ckpt-1100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-02-19:46:21\n",
      "INFO:tensorflow:Saving dict for global step 1100: average_loss = 51.068577, global_step = 1100, label/mean = 23.321775, loss = 1611.8519, prediction/mean = 23.780794\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1100: models\\model_20190302_144601\\model.ckpt-1100\n",
      "INFO:tensorflow:global_step/sec: 64.7619\n",
      "INFO:tensorflow:loss = 1102.1165, step = 1101 (1.545 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1200 into models\\model_20190302_144601\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-02T19:46:22Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from models\\model_20190302_144601\\model.ckpt-1200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-02-19:46:22\n",
      "INFO:tensorflow:Saving dict for global step 1200: average_loss = 49.72153, global_step = 1200, label/mean = 23.321775, loss = 1569.3358, prediction/mean = 21.39926\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1200: models\\model_20190302_144601\\model.ckpt-1200\n",
      "INFO:tensorflow:global_step/sec: 63.5788\n",
      "INFO:tensorflow:loss = 1405.806, step = 1201 (1.572 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1263 into models\\model_20190302_144601\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-02T19:46:23Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from models\\model_20190302_144601\\model.ckpt-1263\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-02-19:46:24\n",
      "INFO:tensorflow:Saving dict for global step 1263: average_loss = 48.288555, global_step = 1263, label/mean = 23.321775, loss = 1524.1075, prediction/mean = 23.739315\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1263: models\\model_20190302_144601\\model.ckpt-1263\n",
      "INFO:tensorflow:Loss for final step: 912.60547.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'average_loss': 48.288555,\n",
       "  'label/mean': 23.321775,\n",
       "  'loss': 1524.1075,\n",
       "  'prediction/mean': 23.739315,\n",
       "  'global_step': 1263},\n",
       " [])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reinstantiating model so that logs aren't polluted by previous runs\n",
    "model_dir = pathlib.Path('models')\n",
    "if not model_dir.exists():\n",
    "    model_dir.mkdir()\n",
    "\n",
    "model_dir = model_dir / datetime.datetime.now().strftime('model_%Y%m%d_%H%M%S/')\n",
    "\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    save_checkpoints_steps=100,\n",
    "    keep_checkpoint_max=20,\n",
    ")\n",
    "\n",
    "estimator = tf.estimator.LinearRegressor(\n",
    "    feature_columns,\n",
    "    model_dir=model_dir,\n",
    "    config=run_config\n",
    ")\n",
    "\n",
    "train_spec = tf.estimator.TrainSpec(\n",
    "    input_fn=get_input_fn(tf.estimator.ModeKeys.TRAIN),\n",
    "    max_steps=None\n",
    ")\n",
    "\n",
    "# Add exporter to EvalSpec\n",
    "exporter = tf.estimator.LatestExporter('exporter', serving_input_fn)\n",
    "\n",
    "eval_spec = tf.estimator.EvalSpec(\n",
    "    input_fn=get_input_fn(tf.estimator.ModeKeys.EVAL),\n",
    "#     exporters=exporter,\n",
    ")\n",
    "\n",
    "tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
